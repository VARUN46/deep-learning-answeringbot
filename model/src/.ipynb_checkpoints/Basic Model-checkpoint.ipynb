{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3607052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\python38\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\python38\\lib\\site-packages (from tensorflow) (1.23.3)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\python38\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\python38\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\python38\\lib\\site-packages (from tensorflow) (13.0.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in c:\\python38\\lib\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\python38\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\python38\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\python38\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\python38\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\python38\\lib\\site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\python38\\lib\\site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\python38\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\python38\\lib\\site-packages (from tensorflow) (4.0.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in c:\\python38\\lib\\site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\python38\\lib\\site-packages (from tensorflow) (1.13.3)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in c:\\python38\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\python38\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in c:\\python38\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in c:\\python38\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in c:\\python38\\lib\\site-packages (from tensorflow) (0.23.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\python38\\lib\\site-packages (from tensorflow) (1.43.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\python38\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\python38\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\python38\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\python38\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.28.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\python38\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (41.2.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\python38\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\python38\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\python38\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.16.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\python38\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\python38\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.10.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\python38\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\python38\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\python38\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "#packages\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e27cee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all imports\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2cf5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check installed packages version if required\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eef31661",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training dataset\n",
    "dataset = pd.read_csv('datasets/BasicModelSet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d5a3614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedDatasetDict = pd.read_csv('datasets/letterEmbedds.csv').set_index('word').T.to_dict()\n",
    "embedDatasetDictVec = pd.read_csv('datasets/letterEmbedds.csv').set_index('embed').T.to_dict()\n",
    "vectorSize = 5\n",
    "#embedDatasetDict['a']['embed']\n",
    "#embedDatasetDictVec[1]['word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bd7a9e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converter functions\n",
    "\n",
    "def convertWordToVector(word):\n",
    "    word = word.lower()\n",
    "    letterArr = [*word]\n",
    "    vectorArr = []\n",
    "    for pos in range(vectorSize):\n",
    "        vectorArr.append(0)\n",
    "    \n",
    "    currentPos = 0\n",
    "    for letter in letterArr:\n",
    "        vectorArr[currentPos] = embedDatasetDict[letter]['embed']\n",
    "        currentPos = currentPos + 1\n",
    "    return vectorArr\n",
    "\n",
    "def convertVectorToWord(vector):\n",
    "    letterArr = []\n",
    "    for vectorVal in vector:\n",
    "        if vectorVal != 0:\n",
    "            letterArr.append(embedDatasetDictVec[vectorVal]['word'])\n",
    "    word = ''.join(letterArr)\n",
    "    return word\n",
    "\n",
    "#tests for converter \n",
    "#convertWordToVector('Var')\n",
    "#convertVectorToWord([22, 1, 18, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "44f7f875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "#prepare vector embeddings\n",
    "dataset['InputVectors'] = dataset['Input'].apply(convertWordToVector)\n",
    "dataset['OutputVectors'] = dataset['Output'].apply(convertWordToVector)\n",
    "dataset.to_csv('datasets/datasetWithEmbeddings.csv')\n",
    "\n",
    "#dataset['OutputVectors'].max()\n",
    "#dataset['OutputVectors']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "95a86229",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type list).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-15e60526e930>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'InputVectors'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'OutputVectors'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
     ]
    }
   ],
   "source": [
    "#model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=vectorSize,\n",
    "        output_dim=vectorSize,\n",
    "        # Use masking to handle the variable sequence lengths\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(dataset['InputVectors'],dataset['OutputVectors'],epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d217cebf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
